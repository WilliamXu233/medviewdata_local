{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ASTRA_DB_API_ENDPOINT = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "ASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7ccb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and initialize the OpenAI embedding model via LangChain\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Import and initialize the OpenAI embedding model via LangChain\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to the Astra DB vector store with specified collection and embedding model\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=\"mdvs\",\n",
    "    embedding=embeddings,\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36150d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Astra DB vector store with specified collection and embedding model\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "# Import and initialize the OpenAI embedding model via LangChain\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def load_and_vectorize_text_file(file_path, chunk_size=500, chunk_overlap=50):\n",
    "    try:\n",
    "        # Read the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text_content = file.read()\n",
    "            \n",
    "        # Create a document with metadata\n",
    "        file_name = file_path\n",
    "        document = Document(\n",
    "            page_content=text_content,\n",
    "            metadata={\"source\": file_path, \"filename\": file_name}\n",
    "        )\n",
    "        \n",
    "        # Initialize text splitter\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "        )\n",
    "        \n",
    "        # Split text into chunks\n",
    "        chunks = text_splitter.split_documents([document])\n",
    "        print(f\"Split document into {len(chunks)} chunks\")\n",
    "        \n",
    "        # Initialize OpenAI embeddings\n",
    "# Import and initialize the OpenAI embedding model via LangChain\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=OPENAI_API_KEY\n",
    "        )\n",
    "        \n",
    "        # Create vector store in AstraDB\n",
    "# Connect to the Astra DB vector store with specified collection and embedding model\n",
    "        vector_store = AstraDBVectorStore.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=embeddings,\n",
    "            collection_name='mdvs',\n",
    "            api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "            token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "        )\n",
    "        \n",
    "        print(f\"Successfully stored {len(chunks)} vectorized chunks in AstraDB collection '{'mdvs'}'\")\n",
    "        return vector_store\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_similar_content(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Search for similar content using the vector store\n",
    "    \n",
    "    Parameters:\n",
    "    query (str): The search query\n",
    "    top_k (int): Number of results to return\n",
    "    \n",
    "    Returns:\n",
    "    list: List of similar documents with scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize embeddings\n",
    "# Import and initialize the OpenAI embedding model via LangChain\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=OPENAI_API_KEY\n",
    "        )\n",
    "        \n",
    "        # Connect to existing vector store\n",
    "        vector_store = AstraDB(\n",
    "            embedding=embeddings,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "            token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "        )\n",
    "        \n",
    "        # Search for similar content\n",
    "        results = vector_store.similarity_search_with_score(query, k=top_k)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error searching: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_multiple_files(directory_path, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Load and vectorize multiple text files from a directory\n",
    "    \n",
    "    Parameters:\n",
    "    directory_path (str): Path to directory containing text files\n",
    "    chunk_size (int): Maximum size of each chunk in characters\n",
    "    chunk_overlap (int): Overlap between chunks in characters\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get all text files in the directory\n",
    "        text_files = [f for f in os.listdir(directory_path) \n",
    "                     if os.path.isfile(os.path.join(directory_path, f)) \n",
    "                     and f.endswith(('.txt', '.md'))]\n",
    "        \n",
    "        # Initialize embeddings and vector store\n",
    "# Import and initialize the OpenAI embedding model via LangChain\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=OPENAI_API_KEY\n",
    "        )\n",
    "        \n",
    "        # Create or connect to vector store\n",
    "        vector_store = AstraDB(\n",
    "            embedding=embeddings,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "            token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "        )\n",
    "        \n",
    "        # Process each file\n",
    "        for file_name in text_files:\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            \n",
    "            # Read file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text_content = file.read()\n",
    "            \n",
    "            # Create document\n",
    "            document = Document(\n",
    "                page_content=text_content,\n",
    "                metadata={\"source\": file_path, \"filename\": file_name}\n",
    "            )\n",
    "            \n",
    "            # Split text\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=chunk_size,\n",
    "                chunk_overlap=chunk_overlap,\n",
    "                length_function=len,\n",
    "            )\n",
    "            chunks = text_splitter.split_documents([document])\n",
    "            \n",
    "            # Add to vector store\n",
    "            vector_store.add_documents(chunks)\n",
    "            print(f\"Added {len(chunks)} chunks from '{file_name}'\")\n",
    "        \n",
    "        print(f\"Successfully processed {len(text_files)} files\")\n",
    "        return vector_store\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing directory: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c38fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Option 1: Process a single file\n",
    "    file_path = \"C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt\"\n",
    "    vector_store = load_and_vectorize_text_file(file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c642b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.823029] air outlet on the machine.     *   Attach the other end of the tubing to your mask.     *\n",
      " If using a humidifier, fill the humidifier chamber with distilled water up to the\n",
      " indicated fill line and insert it into the machine. 3.  **Power the CPAP machine:**     *\n",
      " Plug the power supply into the machine and then into a power outlet.\n",
      " Chunk 568 | Source: https://freestyleserver.com/Payloads/IFU/2017july/ART22813-003_rev [{'source': 'C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt', 'filename': 'C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt'}]\n",
      "* [SIM=0.816094] Getting used to your CPAP therapy can be challenging and there may be different equipment\n",
      " options that will work better for your personal comfort needs, so do\n",
      " Chunk 580 | Source: https://freestyleserver.com/Payloads/IFU/2017july/ART22813-003_rev\n",
      "A_Web.pdf  n’t hesitate to reach out!  Not sure who your medical equipment supplier is? We\n",
      " can help. Fill out our Contact Us form or call us at 1-800-424-0737.   How do I clean my [{'source': 'C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt', 'filename': 'C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt'}]\n",
      "* [SIM=0.806049] one end of the tubing to the air outlet on the machine.     *   Attach the other end of\n",
      " the tubing to your mask.     *   If using a humidifier, fill the humidifier chamber with\n",
      " distilled water up to the indicated fill line and insert it into the mach\n",
      " Chunk 570 | Source: https://freestyleserver.com/Payloads/IFU/2017july/ART22813-003_rev\n",
      "A_Web.pdf  ine. 3.  **Power the CPAP machine:**     *   Plug the power supply into the [{'source': 'C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt', 'filename': 'C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt'}]\n",
      "* [SIM=0.805119] CPAP machine parts and can I sign up for a replacement program?   It’s important to\n",
      " regularly inspect, clean and replace your CPAP supplies, which can be affected by dirt and\n",
      " general wear. You should regularly check the water tub, air tubing and\n",
      " Chunk 583 | Source: https://freestyleserver.com/Payloads/IFU/2017july/ART22813-003_rev\n",
      "A_Web.pdf  air filter for any signs of wear or damage.  Here are some replacement tips for [{'source': 'C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt', 'filename': 'C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt'}]\n",
      "* [SIM=0.799640] CPAP machine and how often?   You should clean your machine weekly. The following can be\n",
      " used as guidance for cleaning your machine; full cleaning instructions can also be found\n",
      " in the machine’s user guide.  How to clean your CPAP machine  Time it takes: 5 minutes\n",
      " Supplies you’ll need to clean your machine:  Sink or tub   Warm,\n",
      " Chunk 581 | Source: https://freestyleserver.com/Payloads/IFU/2017july/ART22813-003_rev [{'source': 'C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt', 'filename': 'C:\\\\Users\\\\hahaha\\\\Downloads\\\\mdvc.txt'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"How to use cpap?\", k=5\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0928env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
